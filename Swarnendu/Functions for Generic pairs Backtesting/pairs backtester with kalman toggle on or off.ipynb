{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as pdr\n",
    "import itertools\n",
    "from datetime import datetime, timedelta, date\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from arch.unitroot import engle_granger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, requests_html\n",
    "warnings.simplefilter('ignore')\n",
    "from numpy import log, polyfit, sqrt, std, subtract\n",
    "import statsmodels.tsa.stattools as ts\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pykalman import KalmanFilter\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as pdr\n",
    "import itertools\n",
    "from datetime import datetime, timedelta, date\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from arch.unitroot import engle_granger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, requests_html\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as pdr\n",
    "import itertools\n",
    "from datetime import datetime, timedelta, date\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from arch.unitroot import engle_granger\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, requests_html\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "cs = pd.read_excel('tickers.xlsx')\n",
    "symbList = cs['Tickers'].values.tolist()\n",
    "df = yf.download(symbList,'2016-9-1','2020-9-1')['Adj Close']\n",
    "print(df.head())\n",
    "df = df.dropna(axis=1, how='all')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[1:]\n",
    "limitPer = len(df) * .50\n",
    "df = df.dropna(thresh=limitPer,axis=1)\n",
    "df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_train = .7\n",
    "train_sample = int(split_train * len(df))\n",
    "# creates combinations of all tickers within the selected index\n",
    "symbol_pairs = list(itertools.combinations(symbList, 2))\n",
    "significance_level = 0.05\n",
    "\n",
    "# selects pairs based on Engle-Granger cointegration test \n",
    "def find_cointegrated_pairs(dataframe):\n",
    "    coint_pairs = []\n",
    "    for y, x in symbol_pairs:\n",
    "            try:\n",
    "                eg_test = engle_granger(dataframe[y], dataframe[x], trend=\"n\")\n",
    "                print(f'{y} - {x} : p-value = {eg_test.pvalue}')\n",
    "                if eg_test.pvalue < significance_level:\n",
    "                    coint_pairs.append((y, x, eg_test.pvalue))\n",
    "            except:\n",
    "                print(f'Oops! Nans detected. The pair: {x} - {y} will be skipped.')\n",
    "    return coint_pairs\n",
    "\n",
    "find_cointegrated_pairs(df[0:train_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pvalue_list_sorted = coint_pairs\n",
    "pvalue_list_sorted = sorted(coint_pairs, key=lambda x: abs(x[2]),reverse = False) \n",
    "top_pairs = 1000\n",
    "top_coint_pairs_list = []\n",
    "\n",
    "for c, pair in enumerate(pvalue_list_sorted, 1):\n",
    "    if len(top_coint_pairs_list) < top_pairs:\n",
    "        \n",
    "        \n",
    "        \n",
    "        top_coint_pairs_list.append((pair[0], pair[1], pair[2]))\n",
    "        print(f'{c}: |{pair[0]: <4}| - |{pair[1]: <4}| p-value: {round(pair[2],3)}')\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hurst(ts):\n",
    "    \"\"\"Returns the Hurst Exponent of the time series vector ts\"\"\"\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, 100)\n",
    " \n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags]\n",
    " \n",
    "    # Use a linear fit to estimate the Hurst Exponent\n",
    "    poly = polyfit(log(lags), log(tau), 1)\n",
    " \n",
    "    # Return the Hurst exponent from the polyfit output\n",
    "    return poly[0]*2.0\n",
    "\n",
    "###############################################################################\n",
    "##### ADF TEST\n",
    "###############################################################################\n",
    "def adf_test(x, y):\n",
    "    df = pd.DataFrame({'y':y,'x':x})\n",
    "    est = sm.OLS(df.y, df.x)\n",
    "    est = est.fit()\n",
    "    df['hr'] = -est.params[0]\n",
    "    df['spread'] = df.y + (df.x * df.hr)\n",
    "    \n",
    "    cadf = ts.adfuller(df.spread)   \n",
    "    return cadf[1] \n",
    "def half_life(spread):\n",
    "    spread_lag = spread.shift(1)\n",
    "    spread_lag.iloc[0] = spread_lag.iloc[1]\n",
    "    \n",
    "    spread_ret = spread - spread_lag\n",
    "    spread_ret.iloc[0] = spread_ret.iloc[1]\n",
    "    \n",
    "    spread_lag2 = sm.add_constant(spread_lag)\n",
    "     \n",
    "    model = sm.OLS(spread_ret,spread_lag2)\n",
    "    res = model.fit()\n",
    "    halflife = int(round(-np.log(2) / res.params[1],0))\n",
    " \n",
    "    if halflife <= 0:\n",
    "        halflife = 1\n",
    "    return halflife\n",
    "    \n",
    "def KalmanFilterAverage(x):\n",
    "    # Construct a Kalman filter\n",
    "    from pykalman import KalmanFilter\n",
    "    kf = KalmanFilter(transition_matrices = [1],\n",
    "                      observation_matrices = [1],\n",
    "                      initial_state_mean = 0,\n",
    "                      initial_state_covariance = 1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=.01)\n",
    "# Use the observed values of the price to get a rolling mean\n",
    "    state_means, _ = kf.filter(x.values)\n",
    "    state_means = pd.Series(state_means.flatten(), index=x.index)\n",
    "    return state_means\n",
    "## Kalman filter regression\n",
    "def KalmanFilterRegression(x,y):\n",
    "    delta = 1e-3\n",
    "    trans_cov = delta / (1 - delta) * np.eye(2) # How much random walk wiggles\n",
    "    obs_mat = np.expand_dims(np.vstack([[x], [np.ones(len(x))]]).T, axis=1)\n",
    "    \n",
    "    kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y is 1-dimensional, (alpha, beta) is 2-dimensional\n",
    "                      initial_state_mean=[0,0],\n",
    "                      initial_state_covariance=np.ones((2, 2)),\n",
    "                      transition_matrices=np.eye(2),\n",
    "                      observation_matrices=obs_mat,\n",
    "                      observation_covariance=2,\n",
    "                      transition_covariance=trans_cov)\n",
    "    \n",
    "    # Use the observations y to get running estimates and errors for the state parameters\n",
    "    state_means, state_covs = kf.filter(y.values)\n",
    "    return state_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backtest(df,sym1,sym2,strategy,spread_calculation,entryZscore,exitZscore,stoploss_Zscore):\n",
    "\n",
    "    \n",
    "    \n",
    "#     \"\"\"BACKTESTING SELECTED PAIR.....\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     dataframe : pandas dataframe\n",
    "#         All assets close prices\n",
    "#     sym1 : string\n",
    "#         The symbol of asset one\n",
    "#     sym2 : string\n",
    "#         The symbol of asset two\n",
    "#     strategy : int\n",
    "#         Trading strategy selection {1,2}.\n",
    "#     roll_beta_window : integer \n",
    "#     zscore_window : integer\n",
    "#     entryZscore : float\n",
    "#     exitZscore : float\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     dataframe[f'Cum_rets: {sym1} {sym2}'], CAGR, sharpe, num_days_in_market : pd.series\n",
    "#         Time series of cumulative returns for selected pair\n",
    "#     comp_ann_return_net, annualised_sharpe_net , num_days_in_the_market : float\n",
    "#         Compound annual growth rate (CAGR) for selected pair\n",
    "#    annualised_sharpe_net , num_days_in_the_market : float\n",
    "#         Sharpe Ratio for selected pair\n",
    "#    num_days_in_the_market : integer\n",
    "#         Number of days the pair is 'in the market'\n",
    "\n",
    "#     \"\"\"\n",
    "    \n",
    "    y = df[sym1]\n",
    "    x = df[sym2]\n",
    "    intersect = y.index.intersection(x.index)\n",
    "    y = y.loc[intersect]\n",
    "    x = x.loc[intersect]\n",
    "\n",
    "    # creates a dataframe using Adj. Close prices from both series\n",
    "    dataframe = pd.DataFrame(index=y.index).dropna()\n",
    "    \n",
    "    dataframe['%s_close' % sym1.lower()] = y\n",
    "    dataframe['%s_close' % sym2.lower()] = x  \n",
    "    if spread_calculation == 1:\n",
    "        state_means = KalmanFilterRegression(KalmanFilterAverage(x),KalmanFilterAverage(y))\n",
    "        dataframe['hr'] = - state_means[:,0]\n",
    "        dataframe['spread'] = y + (x * dataframe.hr)\n",
    "        halflife = half_life(dataframe['spread'])\n",
    "    if spread_calculation == 2:\n",
    "        est = sm.OLS(y,x)\n",
    "        est = est.fit()\n",
    "        dataframe['hr'] = -est.params[0]\n",
    "\n",
    "        dataframe['spread'] = y + (x * dataframe.hr)\n",
    "        halflife = half_life(dataframe['spread'])\n",
    "    \n",
    "\n",
    "    ##############################################################\n",
    "    \n",
    "\n",
    "    ##########################################################\n",
    "\n",
    "    meanSpread = dataframe.spread.rolling(window=halflife).mean()\n",
    "    stdSpread = dataframe.spread.rolling(window=halflife).std()\n",
    "    \n",
    "        \n",
    "    dataframe['zScore'] = (dataframe.spread-meanSpread)/stdSpread\n",
    "   \n",
    "\n",
    "    # selects a trading model : 1 or 2\n",
    "    #     :1 (standard model): buy/sell when z-score reach an entry threshold, \n",
    "    #        and exit when z-score reaches exit threshold.\n",
    "    #     :2 (alternative model): buy/sell when z-score reach an entry threshold, \n",
    "    #        and the current z-score level is lower/higher that the previous one.\n",
    "\n",
    "    if strategy == 1:\n",
    "    # code below (only for model == 1) borrowed from (https://www.pythonforfinance.net/)\n",
    "        dataframe['long_entry'] = ((dataframe.zScore < - entryZscore) & ( dataframe.zScore.shift(1) > - entryZscore)) \n",
    "        dataframe['long_exit'] = ((dataframe.zScore > - exitZscore) & (dataframe.zScore.shift(1) < - exitZscore)) \n",
    "        dataframe['stop_loss_exit_long'] = ((dataframe.zScore < - stoploss_Zscore) & ( dataframe.zScore.shift(1) > - stoploss_Zscore))\n",
    "        dataframe.loc[dataframe['long_entry'],'pos_long'] = 1 \n",
    "        dataframe.loc[dataframe['long_exit'],'pos_long'] = 0 \n",
    "        dataframe.loc[dataframe['stop_loss_exit_long'],'pos_long'] = 0\n",
    "        dataframe['pos_long'][0] = 0 \n",
    "        dataframe['pos_long'] = dataframe['pos_long'].fillna(method='pad') \n",
    "\n",
    "        #calculate when portfolio is SHORT\n",
    "        dataframe['short_entry'] = ((dataframe.zScore > entryZscore) & ( dataframe.zScore.shift(1) < entryZscore))\n",
    "        dataframe['short_exit'] = ((dataframe.zScore < exitZscore) & (dataframe.zScore.shift(1) > exitZscore))\n",
    "        dataframe['stop_loss_exit_short'] = ((dataframe.zScore <  stoploss_Zscore) & ( dataframe.zScore.shift(1) >  stoploss_Zscore))\n",
    "        dataframe.loc[dataframe['short_entry'],'pos_short'] = -1\n",
    "        dataframe.loc[dataframe['short_exit'],'pos_short'] = 0\n",
    "        dataframe.loc[dataframe['stop_loss_exit_short'],'pos_short'] = 0\n",
    "        dataframe['pos_short'][0] = 0\n",
    "        dataframe['pos_short'] = dataframe['pos_short'].fillna(method='pad')\n",
    "    \n",
    "    if strategy == 2:\n",
    "        dataframe['long_entry'] = ((dataframe.zScore < -entryZscore) & ( dataframe.zScore < dataframe.zScore.shift(1))) \n",
    "        dataframe.loc[dataframe['long_entry'],'pos_long'] = 1 \n",
    "        dataframe['pos_long'] = dataframe['pos_long'].fillna(0) \n",
    "        dataframe['long_exit'] = ((dataframe['pos_long'] == 0) & ( dataframe['pos_long'].shift(1) == 1))\n",
    "        dataframe['short_entry'] = ((dataframe.zScore > entryZscore) & ( dataframe.zScore > dataframe.zScore.shift(1)))\n",
    "        dataframe.loc[dataframe['short_entry'],'pos_short'] = -1\n",
    "        dataframe['pos_short'] = dataframe['pos_short'].fillna(0)\n",
    "        dataframe['short_exit'] = ((dataframe['pos_short'] == 0) & ( dataframe['pos_short'].shift(1) == -1)) \n",
    "        \n",
    "    # combine longs/shorts and remove Look ahead bias by lagging the signal\n",
    "    dataframe['position'] = dataframe['pos_long'].shift(1) + dataframe['pos_short'].shift(1)\n",
    "\n",
    "    #########################################\n",
    "    # Override entry/exit columns with entry/exit data \n",
    "    dataframe['long_entry'] = ((dataframe.pos_long.shift(1) == 1) & ((dataframe.position - dataframe.position.shift(1)) == 1)) * 1\n",
    "    dataframe['long_exit'] = ((dataframe.long_exit == True) & (dataframe.position == 1)) * 1\n",
    "    dataframe['stop_loss_long_exit'] = ((dataframe.stop_loss_exit_long == True) & (dataframe.position == 1)) * 1\n",
    "    dataframe['short_entry'] = ((dataframe.pos_short.shift(1) == -1)  & ((dataframe.position - dataframe.position.shift(1)) == -1)) * 1\n",
    "    dataframe['short_exit'] = ((dataframe.short_exit == True) & (dataframe.position == -1)) * 1\n",
    "    dataframe['stop_loss_short_exit'] = ((dataframe.stop_loss_exit_short == True) & (dataframe.position == -1)) * 1\n",
    "    \n",
    "\n",
    "    # calculates adjusted spread using using current prices and hedge ratio from previous bar (avoiding look-ahead bias)\n",
    "    dataframe['test_spread_adj'] = dataframe.iloc[:, 0] + (dataframe['hr'].shift(1) * dataframe.iloc[:, 1])\n",
    "    \n",
    "    dataframe['pct_ret'] = ((dataframe['test_spread_adj'] - dataframe['spread'].shift(1)) / \n",
    "                        (dataframe.iloc[:, 0].shift(1) + (abs(dataframe['hr'].shift(1)) * dataframe.iloc[:, 1].shift(1))))\n",
    "\n",
    "    # calculates actual return for a day according to your position\n",
    "    dataframe['port_ret'] = dataframe['position'] * dataframe['pct_ret'] \n",
    "    dataframe['port_ret'].fillna(0.0, inplace=True)\n",
    "\n",
    "    # trading fees (set here as 0.025%:  slippage + transaction fees, for example you pay 0.25 USD per 1,000 value of trade)\n",
    "    tr_costs = 0.00025\n",
    "    dataframe['tr_cost_paid'] = (dataframe.long_entry | dataframe.long_exit | dataframe.short_entry | dataframe.short_exit | dataframe.stop_loss_exit_short | dataframe.stop_loss_exit_long)\n",
    "    dataframe['port_ret_net'] = dataframe['port_ret'] - ( tr_costs * dataframe['tr_cost_paid'])\n",
    "\n",
    "    # cumulative portfolio return gross and net\n",
    "    dataframe['cum_port_ret_net'] = (dataframe['port_ret_net'] + 1.0).cumprod()\n",
    "    \n",
    "    # calculates Sharpe Ratio\n",
    "    try:\n",
    "        annualised_sharpe_net = np.sqrt(252) * dataframe['port_ret_net'].mean() / dataframe['port_ret_net'].std()\n",
    "    except ZeroDivisionError:\n",
    "        annualised_sharpe_net = 0.0\n",
    "    # calculates CAGR   \n",
    "    end = dataframe.cum_port_ret_net.iloc[-1]\n",
    "    start = dataframe.cum_port_ret_net.iloc[0]\n",
    "    days = len(dataframe.cum_port_ret_net)\n",
    "    comp_ann_return_net = ((end / start) ** (252/days))  - 1.0  \n",
    "    \n",
    "    # calculates number of days the pair is 'in the market'\n",
    "    num_days_in_the_market = len(dataframe.query(\"position == 1 or position  == -1\")['port_ret'])\n",
    "    \n",
    "    # calculate sum of long and short entries\n",
    "    num_trades_long = dataframe.query('long_entry == True')['long_entry'].sum()\n",
    "    num_trades_short = dataframe.query('short_entry == True')['short_entry'].sum()\n",
    "    stoploss_long = dataframe.query('stop_loss_long_exit == True')['stop_loss_long_exit'].sum()\n",
    "    stoploss_short = dataframe.query('stop_loss_short_exit == True')['stop_loss_short_exit'].sum()\n",
    "    \n",
    "    # calculates total trading costs paid\n",
    "    approx_tr_costs = (num_trades_long + num_trades_short) * tr_costs\n",
    "    #pd.set_option('display.max_rows', 500)\n",
    "    \n",
    "    dataframe[f'Cum_rets: {sym1} {sym2}'] = dataframe['cum_port_ret_net']\n",
    "    dataframe[f'Zscore: {sym1} {sym2}'] = dataframe['zScore']\n",
    "    \n",
    "    return dataframe[f'Cum_rets: {sym1} {sym2}'], comp_ann_return_net, annualised_sharpe_net , num_days_in_the_market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PERFORMS BACKTEST for the whole portfolio of pairs\n",
    "threshold1 = 0.15\n",
    "threshold2 = 1\n",
    "all_cum_returns = []\n",
    "print(f'Bactest for period: {df[train_sample:].index[0]} - {df[train_sample:].index[-1]}')\n",
    "print(f'Net performance statistics (after transaction costs) for total number of pairs: {len(top_coint_pairs_list)}' )\n",
    "\n",
    "for pair in top_coint_pairs_list:\n",
    "    cum_returns, CAGR, sharpe, num_days_in_market = backtest(df[train_sample:], pair[0],pair[1], strategy = 1, spread_calculation = 2, entryZscore = 2.0, exitZscore = 0,stoploss_Zscore = 4)\n",
    "    if CAGR > threshold1:\n",
    "        if sharpe > threshold2:\n",
    "            all_cum_returns.append(cum_returns)\n",
    "            print(f' The pair {pair[0]}-{pair[1]}-> CAGR: {CAGR}, Sharpe: {sharpe}, Number of days in trade: {num_days_in_market}')\n",
    "    \n",
    "    #prints equity curve of each pair (for too many pairs the legend does not fit to the image)\n",
    "            cum_returns.plot(figsize=(22,14),legend=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " PERFORMS BACKTEST for the whole portfolio of pairs\n",
    "threshold1 = 0.15\n",
    "threshold2 = 1\n",
    "all_cum_returns = []\n",
    "print(f'Bactest for period: {df[train_sample:].index[0]} - {df[train_sample:].index[-1]}')\n",
    "print(f'Net performance statistics (after transaction costs) for total number of pairs: {len(top_coint_pairs_list)}' )\n",
    "\n",
    "for pair in top_coint_pairs_list:\n",
    "    cum_returns, CAGR, sharpe, num_days_in_market = backtest(df[train_sample:], pair[0],pair[1], strategy = 1, spread_calculation = 2, entryZscore = 2.0, exitZscore = 0,stoploss_Zscore = 4)\n",
    "    if CAGR > threshold1:\n",
    "        if sharpe > threshold2:\n",
    "            all_cum_returns.append(cum_returns)\n",
    "            print(f' The pair {pair[0]}-{pair[1]}-> CAGR: {CAGR}, Sharpe: {sharpe}, Number of days in trade: {num_days_in_market}')\n",
    "    \n",
    "    #prints equity curve of each pair (for too many pairs the legend does not fit to the image)\n",
    "            cum_returns.plot(figsize=(22,14),legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PLOTS PORTFOLIO EQUITY CURVE\n",
    "total_returns = 0\n",
    "for equity_curve in all_cum_returns:\n",
    "    total_returns += equity_curve \n",
    "total_returns = total_returns/len(all_cum_returns)\n",
    "total_returns.plot(style = 'b--', figsize=(18,12))\n",
    "\n",
    "total_returns_pct_chg = total_returns.pct_change()\n",
    "total_returns_pct_chg\n",
    "\n",
    "try:\n",
    "    portfolio_sharpe_net = np.sqrt(252) * total_returns_pct_chg.mean() / total_returns_pct_chg.std()\n",
    "except ZeroDivisionError:\n",
    "    portfolio_sharpe_net = 0.0\n",
    "\n",
    "end = total_returns.iloc[-1]\n",
    "start = total_returns.iloc[0]\n",
    "days = len(total_returns)\n",
    "portfolio_cagr_net = ((end / start) ** (252/days))  - 1.0  \n",
    "\n",
    "print(f'Portfolio of pairs performance:')\n",
    "print(f'CAGR: {round(portfolio_cagr_net,4)}, Sharpe Ratio: {round(portfolio_sharpe_net,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quantstats as qs\n",
    "threshold_date = '2019-09-01'\n",
    "qs.reports.full(total_returns[threshold_date:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
